# Individual Case Analysis: Jiri Otoupal

## Participant Profile
- **Experience**: 8 years (Python, C++, Java, Kotlin)
- **Current Role**: Senior developer in cybersecurity & AI sales startup
- **AI Usage**: Cursor IDE with Claude 3.5, avoids GitHub Copilot
- **Interview**: 57 minutes (shortest due to technical issues), May 9, 2025

## Step 1: Initial Impressions and Reflexive Positioning

### First Listening Notes
Despite technical interruptions, Jiri provided intense, concentrated insights. His pre-ChatGPT model training experience brings unique perspective on limitations. Strong opinions delivered matter-of-factly.

### Researcher Reflexivity
His resistance to phenomenological format initially frustrated me. Later recognized this as valuable data about developer communication preferences. His technical precision reminded me to balance phenomenological depth with participant comfort.

## Step 2: Experiential Themes Emerging from Analysis

### Theme 1: Control Through Memory Erasure
**"Delete history and start fresh"**

Most radical control strategy observed:
- "Jakmile on se vychýlí... musel zasít zpátky na začátek... smazat tu historii celou" [50:24]
- Complete context destruction as solution
- Refuses to negotiate with accumulated errors

### Theme 2: Risk Compartmentalization
**"Personal projects only"**

Strict boundary management:
- "Ty žínky jsou strašně problematický v tom, že oni strašně rádi upravují něco, co nemají upravovat. AV práci si to nemůžu dovolit" [18:02]
- AI for experiments, not production
- Risk awareness shapes adoption

### Theme 3: Team Trust Erosion
**"Extreme distrust emerges"**

Social cost of AI adoption:
- "Jakmile jsou používaní v týmech. Tak je to obrovský problém... je tam většinou nedůvěra velká" [56:01]
- Individual efficiency destroys collective trust
- Sees but cannot solve social dilemma

### Theme 4: Efficiency as Primary Motivator
**"Skip boring, reach interesting"**

Clear instrumental use:
- "Ten agent vlastně díky tomu, že on mi pomáhá dělat ty nudný a otravný věci rychleji, tak mám daleko větší... energii dělat projekty" [45:16]
- AI as path to meaningful work
- Dopamine optimization strategy

### Theme 5: Agent as Directionless Junior
**"Like junior making things worse trying to help"**

Consistent developmental metaphor:
- "Je to vlastně nějakej stroj, kterej dělá nějakej nějakej úkol. Ale ten stroj nedokáže. To vlastně udělat sám" [44:28]
- Requires constant supervision
- Familiar frustration pattern

### Theme 6: Technical Context Limitations
**"Doesn't see the whole picture"**

Specific technical frustrations:
- Agent imports Java libraries for Kotlin project
- Can't maintain consistent context across files
- Hallucinates when knowledge gaps exist

## Step 3: Psychological Needs Analysis (SDT Lens)

### Autonomy
- **Extreme control measures**: Memory erasure as ultimate autonomy
- **Context refusal**: Won't accept AI's accumulated assumptions
- **Clear boundaries**: Production vs. personal projects

### Competence
- **Efficiency gains**: 5x faster prototyping claimed
- **Learning enhancement**: Learned Kotlin via AI
- **Awareness of limitations**: Knows when AI fails

### Relatedness
- **Team relationship damage**: AI creates suspicion
- **Isolation preference**: "AI doesn't judge me"
- **Social cost awareness**: Sees but accepts trade-off

## Step 4: Temporal Dimensions

### Past
- Pre-ChatGPT ML experience shapes expectations
- Traditional debugging skills remain valued

### Present
- Selective, boundary-conscious adoption
- Personal exploration, professional caution

### Future
- Expects continued AI use with same boundaries
- No vision of transformed practice
- Incremental rather than revolutionary change

## Step 5: Experiential Qualities

### Emotional Restraint
Unlike others' dramatic responses:
- Frustration described clinically
- Success noted without celebration
- Pragmatic acceptance of limitations

### Technical Precision
Most specific about failures:
- Exact library conflicts noted
- Context window limitations understood
- Pattern recognition of AI errors

### Social Awareness
Unique focus on collective impacts:
- Team dynamics observation
- Trust erosion recognition
- Individual-collective tension

## Step 6: Unique Contributions to Cross-Case Analysis

1. **Memory Erasure Strategy**: Most radical autonomy preservation
2. **Team Trust Concerns**: Only participant emphasizing social costs
3. **Risk Boundaries**: Clearest production/personal separation
4. **Pre-ChatGPT Perspective**: Historical context on AI limitations

## Step 7: Key Interpretative Insights

### The Conservative Innovator
Jiri embodies paradox:
- Uses cutting-edge tools
- Maintains traditional boundaries
- Innovates within constraints

### Trust as Technical and Social Problem
Unique dual awareness:
- Technical trust (via testing/verification)
- Social trust (via transparency/competence)
- Cannot solve latter with former

### Efficiency Without Transformation
Unlike others' identity shifts:
- Same developer, faster output
- Tool adoption, not role change
- Augmentation without transformation

## Step 8: The Memory Erasure Phenomenon

Jiri's unique strategy deserves special attention:

**When used**: "Jakmile on se vychýlí až moc ze směru"
**Method**: Complete context deletion
**Result**: "pak to funguje"

This represents:
- Ultimate autonomy assertion
- Refusal of AI's interpretive accumulation
- Clean slate as control mechanism
- Cognitive rather than emotional response

## Summary: Jiri's Lived Experience

Jiri's AI experience is characterized by **controlled experimentation within strict boundaries**. His approach is uniquely defensive - using AI enthusiastically for personal projects while maintaining complete separation from professional work. This isn't fear but calculated risk management.

The memory erasure strategy represents the most extreme autonomy preservation observed. Where others negotiate or guide, Jiri simply deletes and restarts. This nuclear option maintains absolute control while revealing deep mistrust of AI's contextual understanding.

His awareness of team trust erosion is unique and troubling. While others focus on individual impacts, Jiri sees AI creating "extreme distrust" in teams. His matter-of-fact acceptance of this cost suggests resignation to inevitable social fragmentation.

The efficiency gains he experiences are substantial but narrowly defined - AI helps skip "boring" work to reach "interesting" problems faster. This instrumental view avoids identity questions plaguing others. He remains a developer who uses tools, not a human transformed by AI collaboration.

Most significantly, his pre-ChatGPT ML experience provides grounded skepticism. He knows what models can and cannot do, expects hallucinations, and plans accordingly. This knowledge enables strategic use while avoiding others' disappointment cycles.

Jiri represents sustainable AI adoption through:
- Radical boundary management
- Extreme autonomy preservation  
- Social cost awareness
- Technical precision
- Identity stability

His experience suggests that developers with deeper AI understanding may actually maintain more conservative adoption patterns, using knowledge to bound rather than expand AI integration.

---

## Audit Trail
- Initial listening: May 9, 2025 (post-interview)
- Four-column analysis: May 22, 2025
- Theme development: May 26, 2025
- Cross-case integration: June 4-5, 2025
- Note: Analysis complicated by technical interruptions but rich despite brevity